{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49e927ff-ae13-441d-b205-ac424c33c8e9",
   "metadata": {},
   "source": [
    "# Predicted and Actual ROI experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e0906e-f05b-41a5-918b-ad9557991741",
   "metadata": {},
   "source": [
    "This notebook will seek to figure out the relationship between Predicted ROI and Actual ROI. Methodology is as follows:\n",
    "1. Create a baseline dataset with randomly generated `label`, `score`, and `amount` columns. \n",
    "2. Calculate TPR and TNR from baseline dataset.\n",
    "3. Create a sample dataset with randomly generated `label`, `score`, and `amount` columns.\n",
    "4. Using the `label` column from the sample dataset and the baseline TPR and TNR metrics, calculate `Predicted ROI`\n",
    "5. Using the rest of the sample dataset, calculate `Actual ROI`\n",
    "6. Compare `Predicted ROI` and `Actual ROI`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd74b62-a390-4bfc-96dc-16ce560bc19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1681e558-29ad-472d-98a2-78f632b11cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a0116fe-f948-4c63-b286-245163eed505",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_matrix = {\n",
    "    \"TP\": 1.5,\n",
    "    \"FP\": -2,\n",
    "    \"TN\": 2,\n",
    "    \"FN\": -1.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3198dcc6-664e-4a40-944f-537f78691f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(row):\n",
    "    if row['score'] == row['label']:\n",
    "        if row['score'] == 0:\n",
    "            return 'TN'\n",
    "        else:\n",
    "            return 'TP'\n",
    "    else:\n",
    "        if row['score'] == 0:\n",
    "            return 'FN'\n",
    "        else:\n",
    "            return 'FP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89bbfdc1-d662-4379-8051-297608d28016",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_preds = [int(np.random.rand() > 0.5) for x in range(20)]\n",
    "baseline_labels = [int(np.random.rand() > 0.5) for x in range(20)]\n",
    "baseline_amount = [int(np.floor(np.random.rand() * 5000)) for x in range(20)]\n",
    "dicto_baseline = {'score' : baseline_preds, 'label' : baseline_labels}\n",
    "df_baseline = pd.DataFrame(dicto_baseline, columns=['score', 'label'])\n",
    "df_baseline['type'] = df_baseline.apply(get_type, axis=1)\n",
    "df_baseline['amount'] = baseline_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5476dee6-f080-4523-a902-b9de574652d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.7,\n",
       "  'recall': 0.7777777777777778,\n",
       "  'f1-score': 0.7368421052631577,\n",
       "  'support': 9},\n",
       " '1': {'precision': 0.8,\n",
       "  'recall': 0.7272727272727273,\n",
       "  'f1-score': 0.761904761904762,\n",
       "  'support': 11},\n",
       " 'accuracy': 0.75,\n",
       " 'macro avg': {'precision': 0.75,\n",
       "  'recall': 0.7525252525252526,\n",
       "  'f1-score': 0.7493734335839599,\n",
       "  'support': 20},\n",
       " 'weighted avg': {'precision': 0.7550000000000001,\n",
       "  'recall': 0.75,\n",
       "  'f1-score': 0.7506265664160401,\n",
       "  'support': 20}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_metrics = classification_report(df_baseline['label'], df_baseline['score'], output_dict=True)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "693036fc-2f4f-4a60-abf5-1d97e5d41c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_TPR = baseline_metrics['1']['recall']\n",
    "baseline_TNR = baseline_metrics['0']['recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08dde82d-3e50-4c76-b8ef-a8b297460e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_preds = [int(np.random.rand() > 0.5) for x in range(20)]\n",
    "sample_labels = [int(np.random.rand() > 0.5) for x in range(20)]\n",
    "sample_amount = [int(np.floor(np.random.rand() * 5000)) for x in range(20)]\n",
    "dicto_sample = {'score' : sample_preds, 'label' : sample_labels}\n",
    "df_sample = pd.DataFrame(dicto_sample, columns=['score', 'label'])\n",
    "df_sample['type'] = df_sample.apply(get_type, axis=1)\n",
    "df_sample['amount'] = sample_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6aaca80-9474-4d77-b9f0-18debc08d0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40496.40404040405\n"
     ]
    }
   ],
   "source": [
    "predicted = 0\n",
    "for ix, row in df_sample.iterrows():\n",
    "    if row['score'] == 0:\n",
    "        predicted += row['amount'] * (baseline_TNR * cost_matrix['TN'] + (1-baseline_TNR) * cost_matrix['FN'])\n",
    "    else:\n",
    "        predicted += row['amount'] * (baseline_TPR * cost_matrix['TP'] + (1-baseline_TPR) * cost_matrix['FP'])\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce277adb-b7ca-4bcd-b050-f24c05a8fa58",
   "metadata": {},
   "source": [
    "At this point, assume we get the labels for the sample dataset, ie. label column is now available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a8ae9ff-4eab-458e-a44c-ba24e0b28d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16939.0\n"
     ]
    }
   ],
   "source": [
    "actual = 0\n",
    "for ix, row in df_sample.iterrows():\n",
    "    actual += row['amount'] * cost_matrix[row['type']]\n",
    "print(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2f8bb8c-0f37-4782-95d3-4548301745c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$-23557.4 difference\n"
     ]
    }
   ],
   "source": [
    "diff = actual - predicted\n",
    "print(f'${round(diff, 2)} difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a0c8636-7b5d-48eb-bf29-7d3e2485efe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-58.17% difference\n"
     ]
    }
   ],
   "source": [
    "diff_percent = diff / predicted\n",
    "print(f'{round(diff_percent * 100, 2)}% difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b3fd88-c3ca-4cd2-b796-9d851378fb75",
   "metadata": {},
   "source": [
    "Take a look at the metrics for the sample to see if discrepancy in actual and predicted can be explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6045ee0-699e-4dd5-9c98-6740aeb0a2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.6, 'recall': 0.6, 'f1-score': 0.6, 'support': 10},\n",
       " '1': {'precision': 0.6, 'recall': 0.6, 'f1-score': 0.6, 'support': 10},\n",
       " 'accuracy': 0.6,\n",
       " 'macro avg': {'precision': 0.6,\n",
       "  'recall': 0.6,\n",
       "  'f1-score': 0.6,\n",
       "  'support': 20},\n",
       " 'weighted avg': {'precision': 0.6,\n",
       "  'recall': 0.6,\n",
       "  'f1-score': 0.6,\n",
       "  'support': 20}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_metrics = classification_report(df_sample['label'], df_sample['score'], output_dict=True)\n",
    "sample_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5675bd0-be26-4894-a51d-e0855261c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_TNR = sample_metrics['0']['recall']\n",
    "sample_TPR = sample_metrics['1']['recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8bdf5c4-c6c8-427d-95b0-1e71ad2463ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.178"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(abs(baseline_TNR - sample_TNR), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a68f356c-db57-4eff-b2d8-9e6caa6ba187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.127"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(abs(baseline_TPR - sample_TPR), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96afc886-2bf2-4415-acfb-230032e2c913",
   "metadata": {},
   "source": [
    "# Concluding remarks\n",
    "Predicted ROI will get close to Actual ROI based on two factors:\n",
    "1. If the predicted TPR/TNR is similar to the baseline TPR/TNR\n",
    "2. to a lesser extent, how well the model performs\n",
    "\n",
    "Essentially, to get an accurate predicted ROI, there must be little to no concept drift and, to a lesser degree, a well-performing model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
